parking_model:
  #settings
  use_gt_occ: true # if true, use gt occ in parking_agent
  # train
  data_dir: './e2e_parking/'
  log_dir: './log/'
  checkpoint_dir: './ckpt'
  log_every_n_steps: 10
  check_val_every_n_epoch: 3

  epochs: 155
  learning_rate: 0.0001
  weight_decay: 0.0001
  batch_size: 20

  training_map: "Town04_Opt_mul"
  validation_map: "Town04_Opt_mul"
  future_frame_nums: 4
  hist_frame_nums: 10
  token_nums: 204
  image_crop: 256

  # bev encoder
  bev_encoder_in_channel: 64
  bev_encoder_out_channel: 258  # 256 + 2

  point_cloud_range: [-16.0, -16.0, -2.0, 16.0, 16.0, 2.0]
  occ_size: [160, 160, 20]
  voxel_out_indices: (0, 1, 2, 3)

  # bev model
  bev_x_bound: [-16.0, 16.0, 0.2]
  bev_y_bound: [-16.0, 16.0, 0.2]
  bev_z_bound: [-10.0, 10.0, 20.0]
  d_bound: [0.5, 12.5, 0.25]
  final_dim: [256, 256]
  bev_down_sample: 8
  use_depth_distribution: 1
  backbone: "efficientnet-b4"

  # segmentation
  seg_classes: 18 # 3
  seg_vehicle_weights: [1.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0] # [1.0, 40.0, 40.0]

  # transformer encoder
  tf_en_dim: 258
  tf_en_heads: 6
  tf_en_layers: 4
  tf_en_dropout: 0.05
  tf_en_bev_length: 256
  tf_en_motion_length: 3

  # transformer decoder
  tf_de_dim: 258
  tf_de_heads: 6
  tf_de_layers: 4
  tf_de_dropout: 0.05
  tf_de_tgt_dim: 15
  lss_downsample: [4, 4, 4] 

  conet_d_bound: [2.0, 50.0, 0.5]
  conet_down_sample: 16

  OccNet_cfg:
    loss_norm: True
    img_backbone:
      pretrained: 'torchvision://resnet50'
      type: 'ResNet'
      depth: 50
      num_stages: 4
      out_indices: (0, 1, 2, 3)
      frozen_stages: 0
      with_cp: True
      norm_eval: False
      style: 'pytorch'
      
    img_neck:
      type: 'SECONDFPN'
      in_channels: [256, 512, 1024, 2048]
      upsample_strides: [0.25, 0.5, 1, 2]
      out_channels: [128, 128, 128, 128]

    img_view_transformer:
      type: 'ViewTransformerLiftSplatShootVoxel'
      loss_depth_weight: 3
      loss_depth_type: 'kld'
      grid_config: null
      data_config: 
        cams: ['CAM_FRONT', 'CAM_FRONT_LEFT', 'CAM_FRONT_RIGHT', 'CAM_BACK', 'CAM_BACK_LEFT', 'CAM_BACK_RIGHT']
        Ncams: 6
        # input_size: (896, 1600)
        # src_size: (900, 1600)
        input_size: (256, 256)
        src_size: (260, 256)
        # image-view augmentation
        resize: (-0.06, 0.11)
        rot: (-5.4, 5.4)
        flip: True
        crop_h: (0.0, 0.0)
        resize_test: 0.00
      numC_Trans: 80
      vp_megvii: False

    occ_encoder_backbone_cfg: 
      type: 'CustomResNet3D'
      depth: 18
      n_input_channels: 80
      block_inplanes: [80, 160, 320, 640]
      out_indices: (0, 1, 2, 3)
      norm_cfg: null

    occ_encoder_neck_cfg:
      type: 'FPN3D'
      with_cp: True
      in_channels: [80, 160, 320, 640]
      out_channels: 256
      norm_cfg: null

    pts_bbox_head:
      type: 'CONetHead'
      norm_cfg: null
      soft_weights: True
      cascade_ratio: 4
      sample_from_voxel: True
      sample_from_img: True
      final_occ_size: [160, 160, 20]
      fine_topk: 15000
      empty_idx: 0
      num_level: null
      in_channels: null
      out_channel: 18
      point_cloud_range: [-16.0, -16.0, -2.0, 16.0, 16.0, 2.0]
      loss_weight_cfg: null
      baseline_mode: "base"

    occ_size: [160, 160, 20]

    empty_idx: 0
